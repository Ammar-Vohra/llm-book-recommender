# ğŸ“š LLM Book Recommender System
An intelligent book recommendation system powered by Large Language Models (LLMs), vector search, and emotion detection. Users can input a book preference in natural language, select a desired category and tone, and receive personalized book suggestions with summaries.


## ğŸš€ Features
ğŸ” Natural Language Book Search â€” Search books by entering descriptive text (e.g., "A book about World War II").

ğŸ—‚ï¸ Category Filter â€” Choose genres like Fiction, Suspense, Romance, etc.

ğŸ­ Tone Filter â€” Select tones like Joy, Sadness, Fear, etc. based on emotion analysis of descriptions.

ğŸ¤– Zero-Shot Classification â€” Auto-categorizes books using LLM embeddings and vector search.

ğŸ’¬ Emotion Detection â€” Uses transformer models to predict the emotional tone of book descriptions.

ğŸ–¼ï¸ Interactive UI â€” Built with Gradio for an intuitive user experience.

ğŸ“˜ Description Viewer â€” Click on any recommended book to read its synopsis.


## ğŸ› ï¸ Tech Stack
| Tool/Library            | Purpose                                  |
| ----------------------- | ---------------------------------------- |
| **Python**              | Core programming language                |
| **Pandas, NumPy**       | Data cleaning and preprocessing          |
| **Matplotlib, Seaborn** | EDA and visualization (optional)         |
| **Langchain**           | Vector search & zero-shot classification |
| **ChromaDB**            | Embedding storage for semantic search    |
| **Transformers**        | Emotion detection from book descriptions |
| **Gradio**              | Web interface/dashboard                  |
| **KaggleHub**           | Dataset retrieval from Kaggle            |
| **python-dotenv**       | Managing environment variables           |


## ğŸ§  Project Workflow
#### 1. Data Collection
* Dataset of books retrieved from Kaggle via KaggleHub.

#### 2. Data Cleaning & Preprocessing
* Used Pandas and NumPy to remove nulls, duplicates, and unnecessary columns.

#### 3. Vector Search & Categorization
* Used LangChain components:
    * TextLoader to read book descriptions.
    * CharacterTextSplitter for chunking text.
    * Chroma as the vector store.
* Performed zero-shot classification to label book categories.
  
#### 4. Emotion Detection
* Applied Hugging Face transformer models to detect emotions in book descriptions.
* Stored results in a new dataset (`books_with_categories.csv`).

#### 5. Frontend with Gradio
* Designed an interactive UI with:

    * Input textbox for user query
    * Dropdowns for category and emotional tone
    * Book cards with clickable details

* Displayed top 16 matching books with their titles and detailed description.

## ğŸ“‚ Project Structure
```bash
llm-book-recommender/
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ books.csv                                    # Original dataset
|   â””â”€â”€ books_cleaned.csv                            # Cleaned dataset
|   â””â”€â”€ books_with_categories.csv                    
|   â””â”€â”€ books_with_emotions.csv                     
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ data-exploration.ipynb                        # Basic Cleaning
â”‚   â””â”€â”€ vector-search.ipynb                          # Used zero-shot classification
â”‚   â””â”€â”€ sentiment-analysis.ipynb                     # Used HF model
â”‚   â””â”€â”€ tagged_description.txt                       # Tagged descriptions for vector search
|
â”œâ”€â”€ gradio-dashboard.py                              # Backend & frontend logic
â”œâ”€â”€ requirements.txt                                 # Required packages
â”œâ”€â”€ .env                                             # API keys and environment configs
â””â”€â”€ README.md                                        # Project documentation

```


## ğŸ§ª How to Run Locally
#### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/llm-book-recommender.git
cd llm-book-recommender
```

#### 2. Create a Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # on linux
venv\Scripts\activate     # on Windows
```

#### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

#### 4. Set Environment Variables
```bash
OPENAI_API_KEY= your_api_key
HUGGINGFACE_API_KEY = your_api_key
```

#### 5. Run the App
```bash
python app.py
```

